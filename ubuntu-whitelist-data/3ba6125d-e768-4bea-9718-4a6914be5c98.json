{
  "uuid": "3ba6125d-e768-4bea-9718-4a6914be5c98",
  "path": "/lib/python3/dist-packages/packaging/_tokenizer.py",
  "size": 5292,
  "modified": "2024-04-02T15:20:50Z",
  "created": "2025-05-13T14:30:44.453510932Z",
  "sha256_hash": "6a50ad6f05e138502614667a050fb0093485a11009db3fb2b087fbfff31327f9",
  "file_type": "Script",
  "permissions": 33188,
  "is_executable": false,
  "is_signed": false,
  "code_signature": null,
  "bundle_info": null,
  "scan_timestamp": "2025-06-01T18:46:34.368050921Z"
}